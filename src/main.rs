mod config;
use config::Config;
use ollama_ai_agents_playground::agent::{
    Agent, ClassificationResult,
    classifier::{self, ClassifierAgent},
};

fn main() -> Result<(), Box<dyn std::error::Error>> {
    let config = Config::get();
    println!("Database path: {}", config.database.path);
    println!("Ollama URL: {}", config.ollama.api.url);

    // Create a tokio runtime for the async example
    let rt = tokio::runtime::Runtime::new().expect("Failed to create Tokio runtime");
    println!();
    println!("ðŸš€ Starting asynchronous processing...");
    println!("ðŸš€ Starting classifier...");
    println!();
    rt.block_on(async {
        let input = "Envie um e-mail para Eva informando que nÃ£o vou poder comparecer Ã  reuniÃ£o e que peÃ§o desculpas por avisar tÃ£o em cima da hora.";
        let classifier_agent = ClassifierAgent::new();
        let result = classifier_agent.process(input).await;
        match result {
            Ok(classification_result) => {
                println!();
                println!("ðŸš€ Classification done!");
                println!("User intent: {}", classification_result.intent);
                println!();
            }
            Err(e) => {
                println!("Failed: {}", e);
            }
        }
    });

    Ok(())
}
